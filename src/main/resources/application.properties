server.port=8801
#httpclient
httpclient.enabled=true
httpclient.maxTotal = 200
httpclient.defaultMaxPerRoute = 20
httpclient.connectTimeout = 1000
httpclient.connectionRequestTimeout = 500
httpclient.socketTimeout = 10000
httpclient.validateAfterInactivity = 30000

#redis
redis.server=10.177.97.32;10.177.97.33;10.177.97.34;10.177.97.35;10.177.97.36;10.177.97.37
redis.port=6379
#资源池中最大连接数
redis.properties.maxTotal=20
#资源池允许最大空闲的连接数
redis.properties.maxIdle=20
#资源池确保最少空闲的连接数
redis.properties.minIdle=20
#当资源池用尽后，调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效
redis.properties.blockWhenExhausted=true
#当资源池连接用尽后，调用者的最大等待时间(单位为毫秒) -1：表示永不超时
redis.properties.maxWaitMillis=300
#向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除
redis.properties.testOnBorrow=true
#向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除
redis.properties.testOnReturn=false

#动态获取配置测试
annotation.test=abc

#spring kafka配置
# 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=192.168.59.130:9092,192.168.59.131:9092,192.168.59.132:9092
spring.kafka.bootstrap-servers=101.200.88.114:9092
# 生产者重试次数
spring.kafka.producer.retries=3
#生产者批量字节数
spring.kafka.producer.batch-size=65536
#生产者缓冲区字节数
spring.kafka.producer.buffer-memory=67108864
#生产者键值序列化实现类
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.ByteArraySerializer
#生产者消息序列化实现类
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.ByteArraySerializer
#消费者是否自动提交
spring.kafka.consumer.enable-auto-commit=false
#spring.kafka.consumer.enable-auto-commit=true
#消费者自动提交间隔时间
spring.kafka.consumer.auto-commit-interval=20000
#消费者键值反序列化实现类
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer
#消费者消息反序列化实现类
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer
#消费者读取数据的策略，可选值：
#earliest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费。
#latest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据。
#none：topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常。
spring.kafka.consumer.auto-offset-reset=latest
#spring.kafka.consumer.auto-offset-reset=earliest
#服务器在回答获取请求之前将阻塞的最长时间
spring.kafka.consumer.fetch-max-wait=30000
#一次调用poll()操作时返回的最大记录数
spring.kafka.consumer.max-poll-records=5
#spring.kafka.consumer.max-poll-records=1
#调用poll()操作的超时时间
spring.kafka.listener.poll-timeout=60000
#客户端等待一次请求响应的超时时间
spring.kafka.consumer.properties.request.timeout.ms=70000
##消费者组id
spring.kafka.consumer.group-id=testConsumerC

#所有需要消费的kafka topic
spring.kafka.topic.total=test_kafka_jump_d

#雪花算法配置
snowflake.defalut-worker-id = 0
snowflake.worker-id-map = {'10.177.97.109':1}